{
  "Pennycook et al., Psych Sci (2020).": [
    {
      "Study": "2",
      "Description": "Study 2 experimentally tested whether subtly making the concept of accuracy salient increased the quality of COVID-19 information that people were willing to share online.",
      "N": 856,
      "Effect size": "Cohen’s d: 0.14 (95%-CI: 0.05-0.23)",
      "Comments": "In the treatment condition, sharing intentions for true headlines were significantly higher than for false headlines."
    }
  ],
  "Pennycook et al., Nature (2021).": [
    {
      "Study": "3",
      "Description": "Treatment condition's impact on sharing discernment.",
      "N": 727,
      "Effect size": "Beta coefficient: 0.05 (95%-CI: 0.03-0.07)",
      "Comments": "Treatment condition significantly increased sharing discernment."
    },
    {
      "Study": "4",
      "Description": "Treatment condition's impact on sharing discernment.",
      "N": 780,
      "Effect size": "Beta coefficient: 0.06 (95%-CI: 0.04-0.09)",
      "Comments": "Treatment condition significantly increased sharing discernment."
    },
    {
      "Study": "5",
      "Description": "Treatment's impact on sharing discernment relative to controls.",
      "N": 671,
      "Effect size": "Beta coefficient: 0.05 (95%-CI: 0.02-0.09)",
      "Comments": "Treatments significantly increased sharing discernment relative to the controls."
    },
    {
      "Study": "5 (Importance treatment)",
      "Description": "Importance treatment's impact on sharing discernment relative to controls.",
      "N": 671,
      "Effect size": "Beta coefficient: 0.04 (95%-CI: 0.01-0.06)",
      "Comments": "Importance treatment significantly increased sharing discernment relative to the controls."
    },
    {
      "Study": "7",
      "Description": "Accuracy message's impact on the average quality of news sources shared.",
      "N": 5379,
      "Effect size": "Beta coefficient: 0.01 (95%-CI: Not specified-Not specified)",
      "Comments": "Accuracy message increased the average quality of the news sources shared."
    }
  ],
  "Epstein et al., Harv Misinfo Review (2021).": [
    {
      "Study": "Evaluation",
      "Description": "Asking participants to judge the accuracy of a non-COVID-19 related headline",
      "N": 935,
      "Effect size": "(no standard effect size available/yet extracted)",
      "Comments": "Intervention increased sharing discernment by roughly 50% (3 percentage points)"
    },
    {
      "Study": "Long Evaluation",
      "Description": "Asking participants to judge the accuracy of a series of 4 non-COVID-19–related headlines (and providing corrective feedback on their responses)",
      "N": 410,
      "Effect size": "(no standard effect size available/yet extracted)",
      "Comments": "Intervention increased sharing discernment by roughly 100% (6 percentage points)"
    },
    {
      "Study": "Importance",
      "Description": "Asking participants how important it was to them to share only accurate news",
      "N": 1046,
      "Effect size": "(no standard effect size available/yet extracted)",
      "Comments": "Intervention increased sharing discernment by roughly 50% (3 percentage points)"
    },
    {
      "Study": "Tips",
      "Description": "Participants were provided with four simple digital literacy tips, taken from an intervention developed by Facebook",
      "N": 906,
      "Effect size": "(no standard effect size available/yet extracted)",
      "Comments": "Intervention increased sharing discernment by roughly 50% (3 percentage points)"
    }
  ],
  "Roozenbeek et al., Psych Sci (2021).": [
    {
      "Study": "1",
      "Description": "Study 1 attempted to replicate the finding that subtly making the concept of accuracy salient increased the quality of COVID-19 information that people were willing to share online.",
      "N": 701,
      "Effect size": "(no standard effect size available/yet extracted)",
      "Comments": "No significant interaction between headline veracity and treatment, β = 0.0046, 95% confidence interval (CI) = [−0.016, 0.026], F(3, 21030) = 1.53, p = .67"
    },
    {
      "Study": "2",
      "Description": "Study 2 recruited additional 882 participants to attempt replication of the finding that subtly making the concept of accuracy salient increased the quality of COVID-19 information that people were willing to share online.",
      "N": 1583,
      "Effect size": "Cohen's d: 0.14 (95%-CI: 0.12-0.17)",
      "Comments": "Significant interaction effect between headline veracity and treatment, β = 0.015, 95% CI = [0.0027, 0.027], F(3, 47490) = 4.52, treatment-group effect size: d = −0.14, 95% CI = [−0.17, −0.12]. The effect size for the control group was directionally similar (d = −0.10, 95% CI = [−0.13, −0.078]), but sharing discernment was still 1.4 times higher in the treatment group than in the control group, an attenuation of about 50% compared with the effect sizes reported in the target study."
    }
  ],
  "Pennycook & Rand, Nat Comms (2022).": [
    {
      "Study": "1",
      "Description": "Internal meta-analysis of 20 studies conducted between 2017 and 2020 aimed to gauge an effect of the various accuracy prompts on sharing discernement across all experiments.",
      "N": 26863,
      "Effect size": "(no standard effect size available/yet extracted)",
      "Comments": "Accuracy prompts significantly increased sharing discernment (interaction between headline veracity and treatment dummies: b = 0.038, z = 7.102, p < 0.001), which translates into a 71.7% increase over the meta-analytic estimate of baseline sharing discernment in the control condition (headline veracity dummy: b = 0.053, z = 6.636, p < 0.001). This increase in discernment was driven by accuracy prompts significantly decreasing sharing intentions for false news (treatment dummy: b = −0.034, z = 7.851, p < 0.001; Fig. 2), which translates into a 10% decrease relative to the meta-analytic estimate of baseline sharing intentions for false news in the control condition (intercept: b = 0.341, z = 15.695, p < 0.001)."
    }
  ],
  "Arechar et al., Nat Hum Beh (2023).": [
    {
      "Study": "1 across 16 countries",
      "Description": "Study conducted in 16 countries across 6 continents experimentally tested whether subtly shifting attention to accuracy increases the veracity of the news people are willing to share.",
      "N": 33480,
      "Effect size": "(no standard effect size available/yet extracted)",
      "Comments": "Prompt condition increased sharing discernment relative to the baseline Sharing condition (meta-analytic estimate, b=0.171, z=4.61, p<0.001). There was significant variation across countries in the magnitude of this effect (χ2=58.57, p<0.001). sharing discernment was also higher in the Tips condition compared to the baseline Sharing condition (meta-analytic estimate, b=0.076, z=4.30, p<0.001)."
    }
  ],
  "Offer-Westort et al., preprint (2022).": [
    {
      "Study": "Evaluation stage: Fact-checks and related articles",
      "Description": "Headline-level treatment: Fact-checking labels and related corrective articles",
      "N": 10531,
      "Effect size": "generalized augmented inverse probability weighted estimator (expressed in percentage points): -0,031 (fact-checks); -0,052 (related articles)",
      "Comments": "The two headline-level treatments are not effective at improving sharing discernment. The fact check treatment is associated with a decrease of 0.6 pp (s.e. = 1.1, Z = −0.51, p = 0.61, 95% CI = [−2.78, 1.63]) in false sharing intentions as compared to control. The related articles treatment increases intention to share false stimuli as compared to control, although this estimate is not statistically distinguishable from zero at conventional significance levels (estimate = 0.8 pp, s.e. = 1.1, Z = 0.71, p = 0.48, 95% CI = [−1.39, 2.98])."
    },
    {
      "Study": "Evaluation stage: Accuracy nudge",
      "Description": "Respondent-level treatment: Accuracy nudge",
      "N": 10531,
      "Effect size": "generalized augmented inverse probability weighted estimator (expressed in percentage points): 0.07 (95%-CI: 0-0.13)",
      "Comments": "The respondent-level treatments are effective. The accuracy nudge and Facebook tips increase sharing discernment by 0.066 (s.e. = 0.032, Z = 2.074, p = 0.04, 95% CI = [0.004, 0.129]) and 0.054 (s.e. = 0.036, Z = 1.501, p = 0.13, 95% CI = [−0.016, 0.123]) relative to control, respectively. These effects are driven by decreases in false sharing of 2.3 pp (s.e. = 1.0, Z = −2.31, p = 0.02, 95% CI = [−4.2, −0.35]) for the accuracy nudge and 2.0 pp (s.e. = 1.1, Z = −1.82, p = 0.07, 95% CI = [−4.11, 0.16]) for Facebook tips, equivalent to 4.9% and 4.2% reductions in false sharing relative to control. Effects on true sharing are not distinguishable from zero at conventional significance levels for either treatment."
    },
    {
      "Study": "Evaluation stage: Facebook tips",
      "Description": "Respondents-level treatment: 5 Facebook tips",
      "N": 10531,
      "Effect size": "generalized augmented inverse probability weighted estimator (expressed in percentage points): 0.05 (95%-CI: -0.02-0.12)",
      "Comments": "The respondent-level treatments are effective. The accuracy nudge and Facebook tips increase sharing discernment by 0.066 (s.e. = 0.032, Z = 2.074, p = 0.04, 95% CI = [0.004, 0.129]) and 0.054 (s.e. = 0.036, Z = 1.501, p = 0.13, 95% CI = [−0.016, 0.123]) relative to control, respectively. These effects are driven by decreases in false sharing of 2.3 pp (s.e. = 1.0, Z = −2.31, p = 0.02, 95% CI = [−4.2, −0.35]) for the accuracy nudge and 2.0 pp (s.e. = 1.1, Z = −1.82, p = 0.07, 95% CI = [−4.11, 0.16]) for Facebook tips, equivalent to 4.9% and 4.2% reductions in false sharing relative to control. Effects on true sharing are not distinguishable from zero at conventional significance levels for either treatment."
    }
  ],
  "Swire et al., J Exp Psychol: Learn Mem Cogn (2017).": [
    {
      "Study": "1",
      "Description": "Study 1 experimentally tested effects of corrections on people’s belief in true and false statements. The experiment used a 2 × 2 × 3 within-between design, with within-subjects factors type of item (myth vs. fact) and type of explanation (the veracity of each statement was explained either briefly or in some detail), and the between-subjects factor retention interval (immediate, 30-min, or 1-week).",
      "N": 93,
      "Effect size": "Partial-Eta squared (η2p): 0.15 (Brief/detailed explanation)",
      "Comments": "Belief rating η2p = .15 (Brief/detailed explanation); .10 (retention interval); Inference question η2p = .16 (Brief/detailed explanation); .12 (retention interval)"
    },
    {
      "Study": "2",
      "Description": "Experiment 2 was a conceptual replication of Experiment 1 but tested older adults. An additional 3-week retention interval condition was also added.",
      "N": 109,
      "Effect size": "Partial-Eta squared (η2p): 0.12 (Brief/detailed explanation)",
      "Comments": "Belief rating η2p = .12 (Brief/detailed explanation); .25 (retention interval); Inference question η2p = .12 (Brief/detailed explanation); .16 (retention interval)"
    }
  ],
  "Huang, Brit J Polit Sci (2017).": [
    {
      "Study": "1",
      "Description": "The study experimentally tested effects of rebuttals on belief in rumors.",
      "N": 631,
      "Effect size": "(no standard effect size available/yet extracted)",
      "Comments": "Some rebuttals did not significantly reduce belief in the rumors. When significant, the effects ranged from 0.29 to 0.86 on a 7-point scale."
    },
    {
      "Study": "2",
      "Description": "The study experimentally tested effects of rebuttals on political trust.",
      "N": 799,
      "Effect size": "(no standard effect size available/yet extracted)",
      "Comments": "Rebuttals improved political trust in some areas and the effects ranged from 0.28 to 0.38 on a 7-point scale."
    }
  ],
  "Gesser-Edelsburg et al., PLOS ONE (2018).": [
    {
      "Study": "1",
      "N": 243,
      "Effect size": "(no standard effect size available/yet extracted)",
      "Comments": "A significant difference was found in the reliability level attributed to the Health Ministry's response between Condition 1 and Condition 2 (sig<0.001), with the average reliability level of the participants in Condition 2 (M = 5.68) being considerably higher than the average reliability level of the participants in Condition 1 (M = 4.64). A significant difference was found between Condition 1 and Condition 2 (sig<0.001), with the average satisfaction with the Health Ministry’s response of Condition 2 participants (M = 5.75) being significantly higher than the average satisfaction of Condition 1 subjects (M = 4.66).  No significant difference was found between Condition 1 and Condition 2 as to further information searching after the Health Ministry’s response. In Condition 1 a significant association was found between satisfaction and this behavioral intention. The higher the participants' satisfaction with the Health Ministry’s response, the more they tended to vaccinate their children (sig<0.01). In Condition 2, no association was not found and this might be attributed to the fact that Condition 2 lacked statistical power for a regression because only seven of the Condition 2 participants said they would not vaccinate their children versus 80 who said they would.."
    }
  ],
  "Paynter et al., PLOS ONE (2019).": [
    {
      "Study": "1",
      "Description": "Study experimentally compared existing training materials aiming to reduce support for (and ultimately use of) non-empirically-supported autism treatments with an optimized debunking treatment in early-childhood intervention staff immediately and after a 6-week delay.",
      "N": 856,
      "Effect size": "Partial-Eta squared (η2p): 0.66 (immediate)",
      "Comments": "η2p = .66 (immediate) [effect size of interaction, i.e. comparison to treatment-as-usual  intervention: η2p = .20] / .45 (delayed) [note the latter is not reported in the paper as there was no longer a significant difference to the treatment-as-usual condition]."
    }
  ],
  "Schmid et al., NHB (2019).": [
    {
      "Study": "Across all 6 studies",
      "Description": "Internal meta-analysis: Rebuttal vs no rebuttal",
      "N": 1773,
      "Effect size": "Hedges' g: 0.49 (95%-CI: 0.37-0.6)",
      "Comments": "Attitude: g=0.49, 95% CI: 0.37, 0.60; intention: g=0.57, 95% CI: 0.46, 0.68"
    },
    {
      "Study": "Across all 6 studies",
      "Description": "Internal meta-analysis: Technique rebuttal vs no technique rebuttal",
      "N": 1773,
      "Effect size": "Hedges' g: 0.31 (95%-CI: 0.22-0.41)",
      "Comments": "Attitude: g = 0.31, 95% CI: 0.22, 0.41; intention: g = 0.31, 95% CI: 0.20, 0.42"
    },
    {
      "Study": "Across all 6 studies",
      "Description": "Internal meta-analysis: Topic rebuttal vs no topic rebuttal",
      "N": 1773,
      "Effect size": "Hedges' g: 0.21 (95%-CI: 0.04-0.38)",
      "Comments": "Attitude: g = 0.21, 95% CI: 0.04, 0.38; intention: g = 0.33, 95% CI: 0.24, 0.43."
    }
  ],
  "Schmid et al., J Cogn (2020).": [
    {
      "Study": "1",
      "Description": "Study 1: Outnumbering and rebuttal, results for rebuttal vs no rebuttal.",
      "N": 101,
      "Effect size": "Partial-Eta squared (η2p): Attitude η²p = .094; Intention η²p = .036",
      "Comments": "Watching the public debate significantly damaged individuals’ attitudes towards vaccination and their intention to get vaccinated, but the rebuttal successfully mitigated this damage. The mitigating effect was only marginally significant on intention to get vaccinated."
    },
    {
      "Study": "2",
      "Description": "Study 2: Outnumbering, forewarning and rebuttal, results for rebuttal vs no rebuttal.",
      "N": 390,
      "Effect size": "Partial-Eta squared (η2p): Attitude η²p = .116; Intention η²p = .124 ; confidence in vaccination η²p = .154",
      "Comments": "Replicating the results from Experiment 1, watching the public debate significantly damaged individuals’ attitudes towards vaccination, including intention to get vaccinated and confidence in vaccination. However, the rebuttal mitigated this damage on all outcome measures, again indicating successful manipulation."
    },
    {
      "Study": "3",
      "Description": "Study 3: outnumbering by delivering multiple rebuttal sources, forewarning and rebuttal, results for rebuttal vs no rebuttal.",
      "N": 390,
      "Effect size": "Partial-Eta squared (η2p): Attitude η²p = .059; Intention η²p = .078 ; confidence in vaccination η²p = .108"
    }
  ],
  "Ecker et al., Cogn Res: Princ Implic (2020).": [
    {
      "Study": "1",
      "Description": "Experiment 1 investigated whether corrections of event-related misinformation are more effective if presented in a narrative format. Experiment 1 targeted misinformation contained in fictional event reports in four conditions. There were two control conditions: One featured no misinformation (noMI condition), another featured a piece of misinformation that was not corrected (noC condition). The two experimental conditions corrected the initially-provided misinformation using either a non-narrative (NN) or narrative (N) correction. The test phase followed the study phase either immediately or after a 2-day delay.",
      "N": 770,
      "Effect size": "Partial-Eta squared (η2p): 0.237 (immediate, non-narrative)",
      "Comments": "Corrections reduced misinformation reliance in inferences regardless of format, both immediately and after a 2-day delay. η2p = .237 (immediate, non-narrative) / .245 (immediate, narrative) / .134 (delayed, non-narrative) / .127 (delayed, narrative) [note these are from contrasts that take full ANOVA model into account; effect sizes from isolated contrasts are larger, .211 - .415]."
    },
    {
      "Study": "2",
      "Description": "Experiment 2 tested whether corrections targeting real-world misconceptions are more effective if they are provided in a narrative versus non-narrative format. Experiment 2 used false claims commonly encountered in the real world, including both true facts and common misconceptions (myths). Claims were followed by explanations that affirmed the facts and corrected the myths. Corrections were either in a non-narrative (NN) or narrative (N) form, and the test was again either immediate or delayed.",
      "N": 776,
      "Effect size": "Partial-Eta squared (η2p): 0.604 (immediate, non-narrative)",
      "Comments": "Corrections reduced misinformation beliefs and misinformation reliance in inferences regardless of format, both immediately and after a 2-day delay.  η2p = .604 (immediate, non-narrative) / .578 (immediate, narrative) / .506 (delayed, non-narrative) / .480 (delayed, narrative) [not reported in paper; calculated from one-sample t-test of belief change against zero; note zero may not be most appropriate baseline as it does not take demand characteristics into account]."
    },
    {
      "Study": "3",
      "Description": "Experiment 3 tested whether narrative corrections would be more effective than non-narrative corrections when debunking worldview-consistent misconceptions. Experiment 3 used real-world false claims that are controversial, including both facts and myths, which were followed by affirmations and corrections. Corrections were again either non-narrative (NN) or narrative (N), and the test was immediate or delayed.",
      "N": 733,
      "Effect size": "Partial-Eta squared (η2p): 0.386 (immediate, non-narrative)",
      "Comments": "Corrections slightly reduced misinformation beliefs and misinformation reliance in inferences regardless of format, both immediately and after a 2-day delay. η2p = .386 (immediate, non-narrative) / .334 (immediate, narrative) / .196 (delayed, non-narrative) / .185 (delayed, narrative) [not reported in paper; calculated from one-sample t-test of belief change against zero; note zero may not be most appropriate baseline as it does not take demand characteristics into account]."
    }
  ],
  "Bowles et al, PLOS ONE (2020).": [
    {
      "Study": "1",
      "Description": "This study experimentally tested the effects of staggered provision of WhatsApp messages targeting COVID-19 misinformation",
      "N": 868,
      "Effect size": "Standard deviation units: Knowledge: 0.07; Behavior: 0.26",
      "Comments": "The study found that WhatsApp messages had substantial effects on knowledge, with treated respondents reporting 0.26σ greater factual knowledge (p < 0.001). Additionally, the treatment resulted in a significant reduction in non-compliance with social distancing, from 37% in the control group to 7% in the treatment group, implying a change in behavior (p < 0.05). These effects were robust across different specifications and not explained by demand effects or social desirability bias."
    }
  ],
  "Porter and Wood, Proc Nat Acad Sci (2021).": [
    {
      "Study": "1",
      "Description": "To understand the effects of corrections in aggregate, a meta-analysis with random effects of the 28 experiments was performed",
      "N": 8000,
      "Effect size": "(no standard effect size available/yet extracted)",
      "Comments": "Corrections reduced belief in falsehoods by 0.59 point on the 5-point scale (P < 0.01). On the same scale, misinformation only increased belief in falsehoods by 0.07 (P > 0.05). Fact-checks thus increase factual accuracy by more than eight times the amount that misinformation degrades factual accuracy."
    }
  ],
  "Winters et al., BMJ (2021).": [
    {
      "Study": "1",
      "Description": "The study explored whether directly debunking misinformation or simply providing correct information is more effective in combating these misconception that typhoid is caused by mosquitoes.",
      "N": 736,
      "Effect size": "(no standard effect size available/yet extracted)",
      "Comments": "The belief that typhoid is caused by mosquitoes was significantly reduced in intervention group A compared with the control group in the ITT analysis (group A: adjusted OR (AOR) 0.29, 95% CI 0.18 to 0.47, see table 3 and online supplemental figure S1). In intervention group B, the reduction was not significant (AOR 0.61, 95% CI 0.39 to 0.95, p=0.029)."
    },
    {
      "Study": "1",
      "Description": "The study explored whether directly debunking misinformation or simply providing correct information is more effective in combating these misconception that typhoid can only co-occur with malaria.",
      "N": 736,
      "Effect size": "(no standard effect size available/yet extracted)",
      "Comments": "The belief that typhoid co-occurs with malaria was significantly reduced in both intervention groups in the ITT analysis (group A: AOR 0.29, 95% CI 0.19 to 0.45; group B: AOR 0.55, 95% CI 0.36 to 0.83)."
    }
  ],
  "Tay et al., Br J Psychol (2022).": [
    {
      "Study": "1",
      "Description": "Study experimentally tested effects of prebunking and debunking interventions on reliance on misinformation, willingness-to-purchase, and tweet sentiment",
      "N": 856,
      "Effect size": "Cohen’s d: 0.89",
      "Comments": "Both debunking and prebunking significantly reduced participants’ number of references to misinformation, with t(625) = −9.60, p = <.001, d = .89, and t(625) = −8.08, p = <.001, d = .73, respectively. The difference between debunking and prebunking conditions was not significant, t(625) = −1.61, p = .108, d = .28."
    },
    {
      "Study": "1",
      "Description": "Study experimentally tested effects of prebunking and debunking interventions on reliance on misinformation, willingness-to-purchase, and tweet sentiment",
      "N": 856,
      "Effect size": "Cohen’s d: 0.46",
      "Comments": "Debunking resulted in more positive sentiments compared to the no-intervention condition, t(625) = 4.65, p = <.001, d = .46, as well as compared to the prebunking condition, t(625) = 2.44, p = .030, d = .24. There was also a significant difference between prebunking and no-intervention conditions, with prebunking resulting in more positive sentiments, t(625) = 2.23, p = .030, d = .22."
    }
  ],
  "Schmid and Betsch, Sci Comm (2022).": [
    {
      "Study": "1",
      "Description": "Study experimentally tested effects of text-based refutations.",
      "N": 1387,
      "Effect size": "Regression coefficient B: Debunking effect short term: −7.06, Debunking effect long term: −1.01 (95%-CI: Debunking effect short term: −9.81; Debunking effect long term: −4.48-Debunking effect short term: −4.31; Debunking effect long term: 2.47)",
      "Comments": "Participants who received the debunking text rated the false antivaccine news headline that mRNA vaccines alter the human genome as less credible compared to the control condition."
    }
  ],
  "Bauer and Wilson, China Quart (2022).": [
    {
      "Study": "1",
      "Description": "The study compared the credibility ratings and political attitudes of the control group, the rumor group, and the rebuttal group.",
      "N": 561,
      "Effect size": "Average treatment effects using difference-in-means tests: 0.36",
      "Comments": "The rebuttal in the study increased support for independence by approximately 0.364 on a 6-point scale."
    }
  ],
  "Schroeder and Kucera, Ed Psyc Rev (2022).": [
    {
      "Study": "1",
      "Description": "A meta-analysis of 473 studies aimed to gauge an effect of refutation texts on learning facilitation.",
      "N": 3869,
      "Effect size": "Hedges g: 0.41 (95%-CI: 0.3-0.51)",
      "Comments": "Refutation text is associated with a positive moderate effect compared to other learning conditions."
    }
  ],
  "Yu et al., Telemat Inform (2022).": [
    {
      "Study": "1",
      "Description": "Comparison of believability across different sources.",
      "N": 2965,
      "Effect size": "F statistic: 2.92",
      "Comments": "The believability of government source was significantly higher than the professional sources, the lay sources, and the mass media source."
    },
    {
      "Study": "1",
      "Description": "Effect of message tone on believability.",
      "N": 2965,
      "Effect size": "F statistic: 5.85",
      "Comments": "The believability of the correction message in a formal tone was higher than in a conversational tone."
    },
    {
      "Study": "1",
      "Description": "Interaction of message tone with topic on correction believability.",
      "N": 2965,
      "Effect size": "F statistic: 9",
      "Comments": "Participants tend to believe the 5G correction more when it was written in a formal tone."
    },
    {
      "Study": "1",
      "Description": "Effect of attitude congruence on correction believability.",
      "N": 2713,
      "Effect size": "F statistic: 218.21",
      "Comments": "Participants with congruent attitudes perceived the correction as more believable."
    },
    {
      "Study": "5",
      "Description": "Moderation effect of tone on believability based on attitude congruence.",
      "N": 2713,
      "Effect size": "F statistic: 5.18",
      "Comments": "Participants with an incongruent attitude perceived formal corrections as more believable than conversational ones."
    }
  ],
  "Batista Pereira et al., JoP (2022).": [
    {
      "Study": "1",
      "Description": "The study exposed participants to common false rumors and tested reactions provided with or without third-party fact-checking information. Corrective information was provided. The study assessed participants' beliefs regarding the story.",
      "N": 2236,
      "Effect size": "(no standard effect size available/yet extracted)",
      "Comments": "Fact-checking corrections did not lead to a significant reduction in misinformation beliefs, regardless of whether they corresponded to political or nonpolitical rumors."
    }
  ],
  "Badrinathan and Chauchard, IJPP (2023).": [
    {
      "Study": "1",
      "Description": "The study presents a pooled model that averages across all rumors to calculate an overall correction effect.",
      "N": 5104,
      "Effect size": "Bivariate OLS Coefficient: -0.2",
      "Comments": "Corrections from various sources, such as experts and fact-checkers, significantly reduce overall rates of beliefs in false rumors."
    }
  ],
  "Porter et al., Ro Soc Op Sci (2023).": [
    {
      "Study": "Wave 1",
      "Description": "Study experimentally tested whether exposure to corrections affects participants' belief accuracy.",
      "N": 10600,
      "Effect size": "Meta-analytic estimate: 0.16",
      "Comments": "Exposure to misinformation corrections increases belief accuracy by 0.16 on a 4-point scale, while exposure to misinformation decreases belief accuracy by 0.09 on the same scale.There is no significant evidence that misinformation and factual corrections affect the intent to vaccinate or views about vaccines."
    },
    {
      "Study": "Wave 2",
      "Description": "Study experimentally tested whether exposure to corrections affects participants' belief accuracy.",
      "N": 2460,
      "Effect size": "Meta-analytic estimate: 0.03",
      "Comments": "The effect is reduced to 0.03 points in Wave 2, very narrowly missing the threshold for statistical significance (p= 0.06, two-tailed)."
    }
  ],
  "Armand, Augsburg et. al, preprint (2021).": [
    {
      "Study": "Baseline survey + Wave 1 and 2 follow-up panel data",
      "Description": "The study experimentally tested whether statements from doctors of locally-renowned hospitals debunking common misconceptions about the virus and reminding about evidence-based policy recommendations improve evidence-based behavior.",
      "N": 3991,
      "Effect size": "(no standard effect size available/yet extracted)",
      "Comments": "Agreement with face mask and hand-washing increased by 0.6 percentage points (0.75% above control). Compliance with policy recommendations rose significantly by 4 percentage points (7.09% above control). Need to verify information with others decreased by 2.3 percentage points (3.54% above control). The doctor's message reduced agreement with misconceptions by 0.8 percentage points."
    }
  ],
  "Hirshleifer et al, preprint (2022).": [
    {
      "Study": "Study 1: Impact on exposure to and engagement with official information posts",
      "Description": "Examination of the effect of treatments on exposure to official information and engagement.",
      "N": "Not Specified",
      "Effect size": "Difference in means: -0.33",
      "Comments": "Users assigned to the treatments listen to 0.33 (25%) fewer minutes of the official posts relative to users assigned the control."
    },
    {
      "Study": "Study 1: Impact on exposure to user-generated useful information",
      "Description": "Effect of treatments on exposure to useful user-generated posts.",
      "N": "Not Specified",
      "Effect size": "Difference in means: -0.14",
      "Comments": "Users assigned to either of the two treatments spend 0.14 (38%) less minutes listening to useful posts than in the control."
    },
    {
      "Study": "Study 1: Impact on exposure to misinformation",
      "Description": "Effect of each treatment on exposure to misinformation.",
      "N": "Not Specified",
      "Effect size": "Difference in means: -0.12",
      "Comments": "Users in the remove treatment are exposed to effectively zero misinformation, a decrease of 97% relative to the control."
    }
  ],
  "Bruns et al., preprint (2023).": [
    {
      "Study": "1",
      "Description": "Study experimentally tested effects of prebunking and debunking interventions on the agreement, credibility assessment and sharing intentions in regards to the misleading article’s claim",
      "N": 5228,
      "Effect size": "Odds ratio: Neutral debunk: 0.51,  European Commission debunk: 0.48 (NA%-CI: Neutral debunk: 0.44, European Commission debunk: 0.41-Neutral debunk: 0.60, European Commission debunk: 0.56)"
    },
    {
      "Study": "1",
      "Description": "Study experimentally tested effects of prebunking and debunking interventions on the agreement, credibility assessment and sharing intentions in regards to the misleading article’s claim",
      "N": 5228,
      "Effect size": "Linear OLS regression as linear estimates: Neutral debunk: -1.20, European Commission debunk: -1.22 (NA%-CI: Neutral debunk: -1.60,  European Commission debunk: -1.62-Neutral debunk:  -0.81,  European Commission debunk: -0.83)"
    },
    {
      "Study": "1",
      "Description": "Study experimentally tested effects of prebunking and debunking interventions on the agreement, credibility assessment and sharing intentions in regards to the misleading article’s claim",
      "N": 5228,
      "Effect size": "Odds ratio: Neutral debunk: 0.54, European Commission debunk: 0.64 (NA%-CI: Neutral debunk: 0.43,  European Commission debunk: 0.51-Neutral debunk: -0.68,  European Commission debunk: -0.79)"
    },
    {
      "Study": "1",
      "Description": "Study experimentally tested effects of prebunking and debunking interventions on the agreement, credibility assessment and sharing intentions in regards to the misleading article’s claim",
      "N": 5228,
      "Effect size": "Odds ratio: Neutral debunk: 1.19, European Commission debunk: 1.24 (NA%-CI: Neutral debunk: 0.98,  European Commission debunk: 1.02-Neutral debunk: 1.45,  European Commission debunk: 1.51)"
    }
  ],
  "Fazio, Harv Misinfo Review (2020).": [
    {
      "Study": "1",
      "Description": "Study experimentally tested whether asking participants to explain why a headline was true or false would affect their intentions to share true and false headlines.",
      "N": 501,
      "Effect size": "Cohen’s d: 0.27",
      "Comments": "In the control condition, over half of the participants (57%) indicated that they would be “likely”, “somewhat likely” or “extremely likely” to share at least one false headline. However, in the explanation condition, only 39% indicated that they would be at least “likely” to share one or more false headlines. A similar decrease occurred in the number of people who indicated that they would be “extremely likely” to share at least one false headline (24% in control condition; 17% in explanation condition)."
    }
  ],
  "Pillai and Fazio, Collabra Psychol (2023).": [
    {
      "Study": "1",
      "Description": "Study experimentally tested whether asking participants to explain why a headline was true or false would affect their intentions to share true and false headlines.",
      "N": 499,
      "Effect size": "Cohen's d: 0.3 (95%-CI: -0.21-0.12)",
      "Comments": "As predicted, asking participants to explain the accuracy of headlines reduced sharing intentions for false headlines, t(498) = -6.62, p < .001, d = 0.30, 95% CI of the difference [-0.21, -0.12], but this effect was not significant for true headlines, t(498) = 0.06, p = .952, d < 0.01, 95% CI of the difference [-0.06, 0.06]."
    }
  ],
  "van der Linden et al., Global Challenges (2017).": [
    {
      "Study": "2",
      "Description": "Study 2 experimentally tested  whether it is possible to “inoculate” people against climate misinformation.",
      "N": 2167,
      "Effect size": "Cohen’s d: 0.75",
      "Comments": "The consensus-treatment (CT) alone elicited a large increase in perceived scientific agreement (d = 1.23 relative to control). In contrast, the (misinformation) countermessage (CM) had a substantial negative influence (d = 0.48) when presented on its own. When participants viewed the messages sequentially (CT | CM), the informational value of the consensus-treatment was negated completely (d = 0.04). As hypothesized, the general (In1 | CM) and detailed (In2 | CM) inoculation interventions were each successful in preserving much of the positive effect of the consensus message in the presence of counterinformation (d= 0.33 and 0.75 or one-third and two-thirds of the initial consensus-treatment effect, respectively)."
    }
  ],
  "Cook et al., PLOS ONE (2017).": [
    {
      "Study": "1",
      "Description": "Experiment 1 tested the effect of inoculation against misinformation that takes the form of ‘false balance’ media coverage regarding climate change.",
      "N": 751,
      "Effect size": "Eta squared: 0.01",
      "Comments": "Experiment 1 found that pre-emptively explaining the potentially misleading effect of false-balance media coverage was effective in neutralizing the negative influence of that type of misleading media coverage. Relative to perceived consensus in the control group (70%), Misinformation only: 63,5%, Consensus + Misinformation: 86%; Inoculation + Misinformation = 70%, Inoculation + Consensus + Misinformation = 84%"
    },
    {
      "Study": "2",
      "Description": "Experiment 2 tested the impact of misinformation that explicitly seeks to manufacture doubt about the scientific consensus on climate change (fake experts). Experiment 2 also tested whether inoculating participants prior to reading misinformation was effective in neutralizing the influence of the misinformation.",
      "N": 400,
      "Effect size": "Eta squared: 0.01",
      "Comments": "Experiment 2 demonstrated that misinformation—in the form of fake experts casting doubt on a scientific consensus—had a polarizing effect on climate attitudes, such that people with low free-market support increased climate acceptance, while people with high free-market support decreased climate acceptance. However, an inoculating message that explains the misinforming technique without mentioning any specifics fully neutralized the polarizing effect of misinformation. Relative to perceived consensus in the control group (54,5%), Misinformation only: 44,5%, Inoculation only: 50,4%; Inoculation + Misinformation:51,6%"
    }
  ],
  "Roozenbeek et al., Palgrave Commun (2019).": [
    {
      "Study": "1",
      "Description": "This study experimentally tested whether learning common misinformation techniques through an inoculation game would impact people's recognition of these techniques as reflected in the judgements of headlines reliability.",
      "N": 14163,
      "Effect size": "Cohen’s d: 0.33",
      "Comments": "The process of active inoculation through playing the Bad News game significantly reduced the perceived reliability of tweets that embedded several common online misinformation strategies. The observed effect sizes range from small to moderate, and are in line with the average effect-size in the context of research on resistance to persuasion."
    }
  ],
  "Roozenbeek et al., Harv Misinfo Review (2020).": [
    {
      "Study": "1",
      "Description": "The study experimentally tested whether playing the Harmony Square game 1) reduces the perceived reliability of misinformation, 2) increases people's confidence in their assessment of the reliability of misinformation, and 3) reduces intentions to share misinformation with others.",
      "N": 681,
      "Effect size": "Cohen’s d: 0.51",
      "Comments": "Reliability of real fake news (d = 0.51), experimenter-designed fake news (d = 0.54), confidence (d = 0.30, d = 0.30), and less sharing (d = 0.28, d = 0.27)."
    }
  ],
  "Basol et al., BD & S (2021).": [
    {
      "Study": "1",
      "Description": "Study 1 experimentally tested whether playing the Go Viral! game will impact people's recognition of manipulativeness of misinformation about COVID-19.",
      "N": 1771,
      "Effect size": "Cohen’s d: 0.52",
      "Comments": "Participants, who played Go Viral!, irrespective of their demographic background (aside from political ideology), found misinformation about COVID-19 significantly more manipulative after playing than before, whereas their assessment of real news did not change in a meaningful sense. The effect sizes are in line with previous studies that have used similar designs."
    },
    {
      "Study": "2.  Go Viral! treatment condition",
      "Description": "This part of study 2 experimentally tested whether playing the Go Viral! game will impact people's recognition of manipulativeness of misinformation about COVID-19, as well as their confidence in their judgements and willingness to share misinformation.",
      "N": 1777,
      "Effect size": "Cohen’s d: 0.56",
      "Comments": "Go Viral game compared to control condition: d=0.56 (manipulativeness), d=0.44 (confidence), d=0.15 (sharing). The game 1) reduces the perceived reliability of misinformation, 2) increases people's confidence in their assessment of the reliability of misinformation, and 3) reduces intentions to share misinformation with others."
    },
    {
      "Study": "2. Infographics treatment condition",
      "Description": "This part of study 2 experimentally tested whether exposing people to prebunking Infographics will impact people's recognition of manipulativeness of misinformation about COVID-19, as well as their confidence in their judgements and willingness to share misinformation",
      "N": 1777,
      "Effect size": "Cohen’s d: 0.17",
      "Comments": "Prebunking infographics compared to control condition: d=0.17 (manipulativeness), d=0.15 (confidence), sharing n.s. This indicates that reading through the UNESCO infographics significantly increases the perceived manipulativeness of COVID-19 misinformation, as well as confidence in their assessment of misinformation manipulativeness. However, for willingness to share there is no significant difference between the Infographics condition and the control group nor the Go Viral! condition. These results are similar (and significant) in all three countries."
    }
  ],
  "Maertens et al., J Exp Psychol: Appl (2021).": [
    {
      "Study": "1",
      "Description": "In Experiment 1, researchers aimed to test the hypothesis that inoculation effects are subject to decay in repeated measures over time. T1 = pretest; T2 = posttest (0 weeks); T3 = posttest (1 week); T4 = posttest (5 weeks); T5 = posttest (13 weeks).",
      "N": 118,
      "Effect size": "Cohen’s d: 1",
      "Comments": "The inoculation effects were significant over all 4 testing points: from the immediate post-test (d = -1.0) to 13 weeks delayed test). Researchers hypothesized that the repeated tests might have confounded the result as they could function as booster sessions or simply testing effects."
    },
    {
      "Study": "2",
      "Description": "In Experiment 2, researchers eliminated the confound of repeated measurement by removing all follow-ups between the direct posttest and the posttest 2 months later.",
      "N": 110,
      "Effect size": "Cohen’s d: 0.69",
      "Comments": "The inoculation effect decays over the course of 9 weeks, rendering the effect no longer significant. The analyses also show that the decay is only partial. Treatment effect at T2 (immediate post-test): d = 0.69. Between T2 and T3 (in 2 months): non-significant inoculation effect retention of 36%, d = −0.35."
    },
    {
      "Study": "3",
      "Description": "In Experiment was identical to Experiment 1 (up to T3, the first follow-up) but changed both the item set and fake-to-real ratio for the follow-up measure. It also omitted the control group.",
      "N": 87,
      "Effect size": "Cohen’s d: 0.72 (95%-CI: 0.48-0.95)",
      "Comments": "The inoculation retention over a 1-week period was similar between the two experimental setups (Exp 1 and 3), thereby finding no evidence for item ratio or item set specific retention effects."
    }
  ],
  "Roozenbeek et al., Sci Adv (2022).": [
    {
      "Study": "1",
      "Description": "Study 1 tested whether a +- 1.5 minute inoculation video about emotional manipulation conferred resistance against the use of this manipulation technique in social media content.",
      "N": 1072,
      "Effect size": "Cohen's d: 0.49",
      "Comments": "Results showed a significant effect of inoculation on participants' ability to discern manipulative from non-manipulative content (p < 0.001, d = 0.49), confidence in identifying manipulative content, (p < 0.001, d = 0.50), trustworthiness discernment (p < 0.001, d = 0.25), and sharing discernment (p < 0.001, d = 0.21)."
    },
    {
      "Study": "2",
      "Description": "Study 2 tested whether a +- 1.5 minute inoculation video about incoherence (mutually exclusive arguments) conferred resistance against the use of this manipulation technique in social media content.",
      "N": 1086,
      "Effect size": "Cohen's d: 0.62",
      "Comments": "Results showed a significant effect of inoculation on participants' ability to discern manipulative from non-manipulative content (p < 0.001, d = 0.62), no significant effect on confidence in identifying manipulative content, (p = 0.471, d = 0.04), a significant effect on trustworthiness discernment (p = 0.002, d = 0.19), and no effect on sharing discernment (p = 0.109, d = 0.10)."
    },
    {
      "Study": "3",
      "Description": "Study 1 tested whether a +- 1.5 minute inoculation video about false dichotomies conferred resistance against the use of this manipulation technique in social media content.",
      "N": 1095,
      "Effect size": "Cohen's d: 0.68",
      "Comments": "Results showed a significant effect of inoculation on participants' ability to discern manipulative from non-manipulative content (p < 0.001, d = 0.68), confidence in identifying manipulative content, (p < 0.001, d = 0.48), trustworthiness discernment (p < 0.001, d = 0.32), and sharing discernment (p < 0.001, d = 0.22)."
    },
    {
      "Study": "4",
      "Description": "Study 2 tested whether a +- 1.5 minute inoculation video about scapegoating conferred resistance against the use of this manipulation technique in social media content.",
      "N": 1080,
      "Effect size": "Cohen's d: 0.28",
      "Comments": "Results showed a significant effect of inoculation on participants' ability to discern manipulative from non-manipulative content (p < 0.001, d = 0.28), confidence in identifying manipulative content, (p < 0.001, d = 0.35), no significant effect on trustworthiness discernment (p = 0.100, d = 0.10), and no effect on sharing discernment (p = 0.067, d = 0.11)."
    },
    {
      "Study": "5",
      "Description": "Study 5 tested whether a +- 1.5 minute inoculation video about ad hominem attacks conferred resistance against the use of this manipulation technique in social media content.",
      "N": 1083,
      "Effect size": "Cohen's d: 0.45",
      "Comments": "Results showed a significant effect of inoculation on participants' ability to discern manipulative from non-manipulative content (p < 0.001, d = 0.45), confidence in identifying manipulative content, (p < 0.001, d = 0.24), trustworthiness discernment (p = 0.002, d = 0.19), and sharing discernment (p < 0.001, d = 0.19)."
    },
    {
      "Study": "6",
      "Description": "Study 6 sought to replicate Study 1, i.e., we tested whether a +- 1.5 minute inoculation video about emotional manipulation conferred resistance against the use of this manipulation technique in social media content. We also tested whether the order of presentation of the outcome measures (technique recognition, trustworthiness and sharing) interacted with the main effect.",
      "N": 1072,
      "Effect size": "Cohen's d: 0.67",
      "Comments": "Results showed a significant effect of inoculation on participants' ability to discern manipulative from non-manipulative content (p < 0.001, d = 0.67), trustworthiness discernment (p < 0.001, d = 0.44), and sharing discernment (p < 0.001, d = 0.34). The order of presentation under each item did not interact significantly with the main effect (p > 0.351)."
    },
    {
      "Study": "7",
      "Description": "Study 6 was conducted on YouTube. We sought to assess whether watching an inoculation video as a YouTube ad subsequently improved people's ability to identify manipulation techniques. We ran 2 of the videos (emotional language, Studies 1 and 6; and false dichotomies, study 3) as YouTube ads and asked each a single survey question, each containing a manipulative headline and asking participants to identify which manipulation technique is used. We administered a total of 6 items, 3 per video. The control group did not watch an inoculation video as a YouTube ad but did answer a survey question.",
      "N": 22632,
      "Effect size": "Cohen's h: 0.09",
      "Comments": "Results showed a significant effect of watching an inoculation video on participants' ability to correctly identify a manipulation technique (Cohen's h = 0.09, p < 0.001)."
    }
  ],
  "Lu et al., JMIR (2023).": [
    {
      "Study": "Meta-analysis variable 1",
      "Description": "Misinformation Credibility Assessment",
      "N": "31 studies out of 42",
      "Effect size": "Cohen's d: -0.36 (95%-CI: -0.5--0.23)",
      "Comments": "Psychological inoculation effectively reduced misinformation credibility. Inoculation effects for misinformation credibility assessment remain significant over time, but decrease after two weeks: Immediately d = –0.37 (–0.54 to –0.19); One week  d = –0.43 (–0.62 to –0.23); Two weeks or more d= –0.19 (–0.34 to –0.04)."
    },
    {
      "Study": "Meta-analysis variable 2",
      "Description": "Real Information Credibility Assessment",
      "N": "26 studies out of 42",
      "Effect size": "Cohen's d: 0.2 (95%-CI: 0.06-0.33)",
      "Comments": "Psychological inoculation effectively improved real information credibility."
    },
    {
      "Study": "Meta-analysis variable 3",
      "Description": "Credibility Discernment",
      "N": "12 studies out of 42",
      "Effect size": "Cohen's d: 0.2 (95%-CI: 0.13-0.28)",
      "Comments": "Psychological inoculation effectively improved credibility discernment."
    },
    {
      "Study": "Meta-analysis variable 4",
      "Description": "Misinformation Sharing Intention",
      "N": "12 studies out of 42",
      "Effect size": "Cohen's d: -0.35 (95%-CI: -0.79-0.09)",
      "Comments": "Psychological inoculation did not effectively reduce misinformation sharing intention."
    },
    {
      "Study": "Meta-analysis variable 5",
      "Description": "Real Information Sharing Intention",
      "N": "11 studies out of 42",
      "Effect size": "Cohen's d: 0.09 (95%-CI: 0.03-0.16)",
      "Comments": "Psychological inoculation effectively improved real information sharing intention."
    },
    {
      "Study": "Meta-analysis variable 6",
      "Description": "Sharing Discernment",
      "N": "8 studies out of 42",
      "Effect size": "Cohen's d: 0.18 (95%-CI: 0.12-0.24)",
      "Comments": "Psychological inoculation effectively improved sharing discernment."
    }
  ],
  "Wong and Wu, J Risk Res (2023).": [
    {
      "Study": "1",
      "N": 122,
      "Effect size": "Cohen's f: 0.09",
      "Comments": "The treatment condition (i.e. playing the fake news game) did not have a significant effect on people’s ability to identify fake news compared to the control group (F(1, 112) = 0.09, p = 0.76)."
    }
  ],
  "Batista Pereira et al., JEPS (2023).": [
    {
      "Study": "1",
      "Description": "A two-wave online survey combined with an experimental intervention conducted during the 2020 mayoral elections in São Paulo, Brazil.",
      "N": 1000,
      "Effect size": "The intent-to-treat estimates from OLS models: -0.12 points in the additive scale of rumor acceptance and -0.24 points in acceptance of the repeated rumor",
      "Comments": "The intervention reduced on average .12 points in the additive scale of rumor acceptance and .24 points in acceptance of the repeated rumor."
    },
    {
      "Study": "2",
      "Description": "A two-wave online survey combined with a similar experimental intervention conducted during the early months of 2022 in São Paulo.",
      "N": 1037,
      "Effect size": "(no standard effect size available/yet extracted)",
      "Comments": "The interventions did not significantly affect subjects’ acceptance of real news, but increased between 0.03 and 0.04 points the rejection of rumors. The treatment has a significant effect (both ITT and CACE) on the differences in acceptance between real and false stories."
    }
  ],
  "Armand, Fracchia et al., preprint (2021).": [
    {
      "Study": "T1: Endorsement",
      "Description": "This study investigates the effect of interventions T1 (endorsement) on the acceptance of the COVID-19 vaccine and trust in institutions.",
      "N": 1419,
      "Effect size": "OLS regression estimate: acceptance:0.08; trust: 0,11"
    },
    {
      "Study": "T2: Endorsement + Social memory",
      "Description": "This study investigates the effect of interventions T2 (Endorsement + Social memory) on the acceptance of the COVID-19 vaccine and trust in institutions.",
      "N": 1419,
      "Effect size": "OLS regression estimate: acceptance:0.14; trust: 0,11"
    },
    {
      "Study": "T3: Endorsement + Social memory + Inoculation",
      "Description": "This study investigates the effect of interventions T2 (Endorsement + Social memory + Inoculation) on the acceptance of the COVID-19 vaccine and trust in institutions.",
      "N": 1419,
      "Effect size": "OLS regression estimate: acceptance:0.27; trust: 0,19"
    }
  ],
  "Garg and Yadav, preprint (2022).": [
    {
      "Study": "1",
      "N": 1301,
      "Effect size": "Beta coefficient (b): 0.107 (false statements); -0.038 (true statements)",
      "Comments": "Intervention increased the ability to identify misinformation by 11 percentage points, but also reduced beliefs in true statements by 4 percentage points."
    }
  ],
  "Bowles et al., preprint (2023).": [
    {
      "Study": "1",
      "Description": "The study examined whether preemptive exposure to fact-checks increased respondents' ability to discern between true and false content.",
      "N": 4541,
      "Effect size": "(no standard effect size available/yet extracted)",
      "Comments": "Consumption of fact-checks increased by 0.65 standard deviations across pooled podcast treatment conditions. Podcast-treated participants became 36 percentage points more likely to report listening to the podcast relative to the control group. Treated respondents who received fact-check quiz incentives increased the number of questions relating to fact-check content that they answered correctly by 0.41 standard deviations. Treated respondents with incentives to consume fact-checks became 0.2 standard deviations more likely to subscribe to Africa Check's content. Any treatment with fact-check quiz incentives increased respondents' discernment between true and false information by 0.06 standard deviations, skepticism of conspiracy theories by 0.1 standard deviations, and information verification knowledge by 0.1 standard deviations. The treatments incentivizing participants to consume fact-checks reduced trust in social media platforms by 0.09 standard deviations. There is no statistically significant effects on information consumption and verification behavior. Any treatment with fact-check quiz incentives reduced sharing of information received via social media by around 0.1 standard deviations. Attitudes and behaviors relating to COVID-19 and government fact-checks delivered by text messages increased an index of COVID-19 knowledge and preventative behavior by 0.14 standard deviations and an index of incumbent government performance by 0.07 standard deviations."
    }
  ],
  "Athey et al., preprint (2023).": [
    {
      "Study": "1",
      "N": 7688,
      "Effect size": "(no standard effect size available/yet extracted)",
      "Comments": "Relative to the No-course baseline sharing rate of 63.9 p.p., the treatment courses decrease the Sharing Rate by 18.1 p.p. (SE = 1.16 p.p.) or approximately 28%. Relative to the Facts baseline, the treatment course decreases the Sharing Rate by 10.4 p.p. (SE = 1.19 p.p.) or approximately 18% relative to the 56.3 p.p. sharing rate for the Facts baseline. The difference between the No-course and Facts baselines of 7.7 p.p (SE = 1.44 p.p.) shows that making misinformation salient to participants on a daily basis does have some beneficial impact on sharing behavior, but the treatment courses are providing educational content beyond this salience effect."
    }
  ],
  "Wineburg et al., Teach Coll Rec (2019).": [
    {
      "Study": "1",
      "Description": "This exploratory expert-novice study aimed to better understand the nature of expertise in the evaluation of online information.",
      "N": 45,
      "Effect size": "(no standard effect size available/yet extracted)",
      "Comments": "For the first task (evaluating articles about bullying on two websites), Fact checkers had a perfect mean score of 2 (SD = 0); historians, 0.7 (SD = 0.95); and students, .16 (SD = 0.37). For the second task (an article at the minimum wage.com), fact-checkers’ conclusions averaged 3.3 (SD = .82) out of 4, versus historians’ average of 1.3 (SD = 1.4) and students’ .52 (SD = 1.16). For the third task (offline article on the court case Vergara v. California, task: researching the funding source), the fact checkers’ conclusions merited a 3.6 (SD = 0.70), versus historians’ 2.4 (SD = 1.3) and students’ 2.3 (SD = 1.5)."
    }
  ],
  "McGrew et al., Br J Educ Psychol (2019).": [
    {
      "Study": "1",
      "Description": "This pilot study investigated whether a focused curricular intervention could improve university students’ ability to make sound judgements of credibility.",
      "N": 67,
      "Effect size": "(no standard effect size available/yet extracted)",
      "Comments": "Overall, students in the treatment group were over twice as likely (2.15 times) to score higher at posttest than at pretest, while students in the control condition were equally likely (1.00 times) to score higher at posttest than at pretest."
    }
  ],
  "McGrew, Comput Educ (2020).": [
    {
      "Study": "1",
      "Description": "This study investigated whether a focused curricular intervention could improve high school students’ online reasoning skills.",
      "N": 68,
      "Effect size": "(no standard effect size available/yet extracted)",
      "Comments": "1. Ad Identification. Change from pre to post was not significant (Z = 1.44; p = .15). 2. Lateral Reading. Pre-to-post change was significant (Z =  3.59; p < .001). 3. Analyzing Evidence. Pre-to-post change was significant (Z =  6.23; p < .001). 4. Claim Research. Pre-to-post change was significant (Z = 3.77; p < .001)."
    }
  ],
  "Donovan et al., Mem Cogn (2020).": [
    {
      "Study": "1",
      "Description": "Study 1 experimentally tested whether opportunities for online search would reduce inaccurate reproductions of information.",
      "N": 231,
      "Effect size": "Partial-Eta squared (η2p): use of inaccurate statements: 0.05; use of accurate statements: 0.13",
      "Comments": "Participants in the search condition (M = 5.17%, SD = 10.97) were less likely to reproduce inaccurate information than were participants in the no-search condition (M = 7.40%, SD = 15.10) [F (1, 214) = 11.01, MS = 0.83, p = .001, ηp2 = .05]. Participants in the search condition produced more correct responses (M = 72.37%, SD = 30.74) than did participants in the no-search condition (M = 59.30%, SD = 35.74), [F (1, 214) = 31.82, MS = 22.25, p < .001, ηp2 = .13]."
    },
    {
      "Study": "2",
      "Description": "Study 2 experimentally tested whether opportunities for online search  would reduce inaccurate reproductions of information. The study was conducted in the lab.",
      "N": 96,
      "Effect size": "Partial-Eta squared (η2p): use of inaccurate statements: 0.14; use of accurate statements: 0.46",
      "Comments": "Participants in the search condition (M = 4.30%, SD = 9.61) used inaccurate information to answer questions less often than did participants in the no-search condition (M = 7.52%, SD = 14.73), [F (1,95) = 14.94, MS = 0.72, p < .001, ηp2 =.14]."
    }
  ],
  "Brodsky et al., Cogn Res: Princ Implic (2021).": [
    {
      "Study": "1",
      "Description": "This field experiment tested the efficacy of teaching university students Digital Polarization Initiative's (DPI) four fact-checking strategies.",
      "N": 230,
      "Effect size": "(no standard effect size available/yet extracted)",
      "Comments": "At posttest, students in DPI sections had an average score of M = 2.22 (SD = 0.92) across the four problems and received a score of 4 on an average of 1.07 problems (SD = 1.07). In contrast, students in control sections had an average score of M = 1.15 (SD = 0.30) and received a score of 4 on an average of 0.03 problems (SD = 0.23). For the self-reported lateral reading at posttest, there was a significant main effect of condition, F(1, 228) = 4.13, p = .043, ηp2 = 0.02, with students in the DPI sections reporting higher use of lateral reading (M = 3.45, SD = 0.84) than students in the control sections (M = 3.25, SD = 0.88). The interaction of time and condition was not significant, F(1, 228) = 1.06, p = .304, ηp2 = 0.01."
    }
  ],
  "Breakstone et al., HKS Misinfo Rev (2021).": [
    {
      "Study": "1",
      "Description": "A treatment-only, pre-and-post intervention in which students in an online, university-level nutrition course received instruction in fact-checking strategies for evaluating the credibility of online sources.",
      "N": 87,
      "Effect size": "(no standard effect size available/yet extracted)",
      "Comments": "Average scores improved from 3.95 points out of 13 at pretest to 7.08 at posttest, an average gain of 3.13 points. A repeated-measures ANOVA revealed that the gains from pretest to posttest were statistically significant, Meandiff = 3.13; F(1, 85) = 136.03, p < .001."
    }
  ],
  "Yang et al., Comput Educ (2021).": [
    {
      "Study": "1",
      "Effect size": "(no standard effect size available/yet extracted)",
      "Comments": "The experimental conditions did not have a significant effect on skepticism toward online information. Meanwhile, the results demonstrated that participants’ intellectual civic skills positively predicted their levels of skepticism toward online information, F(1, 204) = 9.12, p = 0.003. With regard to information discernment skills, there were significant differences among the experimental conditions, F(2, 204) = 4.62, p = 0.011. Pairwise comparisons revealed that participants in the game group showed statistically significant higher achievement compared to those in the control group (p = 0.003). On the other hand, the quiz group did not show difference compared to the control group (p = 0.267), and showed marginally significant difference to the game group (p = 0.064).The game was equally effective for the participants with various levels of perceived intellectual civic skills."
    }
  ],
  "Kobayashi et al., PLOS ONE (2021).": [
    {
      "Study": "1",
      "Description": "Investigated the average treatment effect of online search on the likelihood of believing misinformation.",
      "N": 1032,
      "Effect size": "(no standard effect size available/yet extracted)",
      "Comments": "Online search reduces the likelihood of believing misinformation on average. 37.94% of the control group believed the misinformation to be true, falling to 25.62% in the treatment group."
    }
  ],
  "Wineburg et al., J Educ Psychol (2022).": [
    {
      "Study": "1",
      "Description": "The present study investigated whether high school students would improve as evaluators of online content on the open Web after completing six 50-minute lessons based on Civic Online Reasoning curriculum taught by their teachers.",
      "N": 499,
      "Effect size": "(no standard effect size available/yet extracted)",
      "Comments": "Students in the treatment condition (n = 271) were more likely to show improvement from pretest to posttest than control students (n = 228), Robust beta coefficient for condition x time(pre-post) = 1.66, SE = .44, t = 3.77, 95% CI (.44, 3.77)."
    }
  ],
  "Panizza et al., Sci Rep (2022).": [
    {
      "Study": "1",
      "Description": "Experiment 1 tested separately the efficacy of pop-up (incl. lateral reading) and monetary incentives, and compared their effects to a control condition with no interventions.",
      "N": 517,
      "Effect size": "Common Language Effect Size: 0.54 (95%-CI: 0.49-0.58)",
      "Comments": "In the first study (whole sample N = 2384), results showed a significant effect of incentive (β=0.293 [0.092, 0.494], z=3.225, p=0.003) and a lack of significance for the pop-up (β=−0.009 [−0.207,0.188], z=−0.103, p=.918). Technique adoption: both incentive and pop-up increased technique adoption ( incentive: β=1.042 [0.527, 1.556], z=4.728, p<0.001; pop-up: β=1.556 [1.065, 2.046], z=7.405, p<0.001), but that the increase was markedly higher with the presence of the pop-up than with monetary incentives (β=0.514 [0.157, 0.871], z=3.362, p<0.001). Participants were more likely to use lateral reading when the source was unknown (stimuli included known sources, such as BBC)."
    },
    {
      "Study": "2",
      "Description": "Experiment 2 replicated the format of the first one, with two main modifications: 1) a pre-screening survey to identify lesser-known sources of information and only used those sources as the basis for the Facebook posts the participants were asked to evaluate; 2) added an experimental condition that included both incentive and pop-up interventions, to test the interaction between the two.",
      "N": 3003,
      "Effect size": "Common Language Effect Size: 0.52 (95%-CI: 0.5-0.54)",
      "Comments": "In the second study, results revealed a significant effect of pop-up on accuracy scores (β=0.137 [−0.018,0.292], z=2.115, p=0.034; Mixed-effects regression with errors clustered by post: p=0.052), but not on correct guessing (β=0.076 [−0.112,0.265], z=0.966, p=0.334). The combination of the two interventions significantly increased both accuracy indices compared to control (accuracy score: β=0.487 [0.268, 0.705], z=5.315, p<0.001; correct guessing: β=0.389 [0.123, 0.654], z=3.496, p<0.001), and that the contribution of incentive was greater than the contribution of pop-up (accuracy score: β=0.213 [−0.007,0.432], z=2.307, p=0.028; correct guessing: β=0.2362 [−0.032,0.504], z=2.103, p=0.047). According to the ordinal logistic regression model, the combination of the two interventions led to a 10.4% [5.4%,14.2%] increase in correct guessing, and a 6.9% [2.8%,12.4%] increase in  correct responses compared to control."
    }
  ],
  "McGrew and Breakstone, AERA Open (2023).": [
    {
      "Study": "1",
      "Description": "A pre-and-post, treatment-only intervention in which Civic Online Reasoning lessons were integrated into ninth grade biology and geography courses at a large suburban high school in the United States. ANOVA was used to measure the significance of the within-participant changes in scores from pretest to posttest.",
      "N": 574,
      "Effect size": "(no standard effect size available/yet extracted)",
      "Comments": "ANOVA revealed he difference in scores from pre to post was statistically significant (Mpre = 2.24, Mpost = 3.75; F (1,572) = 299.91, p < .001). Results also indicated significant main effects of time (ATStime = 301.88, p < .001) and class type (ATS class = 149.44, p < .001), which suggested that students’ scores were significantly different from pretest to posttest and that there were significant differences in scores across class type (general vs. honors). The results also indicate a significant interaction between class type and time (ATS class x time = 13.14, p < .001), which supports a rejection of the null hypothesis that students’ scores exhibited the same patterns from pretest to posttest across class type (general versus honors)."
    }
  ],
  "Fendt et al., Comp Hum Beh (2023).": [
    {
      "Study": "1",
      "Description": "A lab-based experiment with at 3X2 factorial design that tested the efficacy of cognitive apprenticeship interventions on participants' abilities to identify 'truthful' and 'fake' news.",
      "N": 312,
      "Effect size": "(no standard effect size available/yet extracted)",
      "Comments": "Training effects on truthful news credibility: The within-subject effect was significant, F(1, 305) = 3.92, p = .049, partial η2 = 0.01 (small effect). The interaction effect datapoint*training type was marginally significant, F(2, 305) = 2.97, p = .053, partial η2 = 0.02 (small effect). There was also a significant interaction effect datapoint*political opinion, F(1, 305) = 7.06, p = .01, partial η2 = 0.02 (small effect). The between-subject effects of training type and trainer education were not significant. There was a significant covariate effect of political opinion, F(1, 305) = 17.53, p < .001, partial η2 = 0.05 (small to medium effect). Training effects on fake news credibility: The within-subject effect was not significant F(1, 305) = 2.62, p = .11. However, there were significant interaction effects datapoint*training type, F(2, 305) = 14.17, p < .001, partial η2 = 0.09 (medium effect) and datapoint*trainer education, F(2, 305) = 5.44, p = .02, partial η2 = 0.02 (small effect). The between-subject effect of training type was significant, F(2, 305) = 18.16, p < .001, partial η2 = 0.11 (medium to large effect). Multiple Bonferroni adjusted comparisons showed significant differences between the written instructions and the control group, p < .001, MDiff = − 0.45, 95%-CI = [0.18, 0.73], as well as between the cognitive apprenticeship and the control group, p < .001, MDiff = 0.64, 95%-CI = [0.38, 0.90]. The difference between the written instructions and the cognitive apprenticeship group was not significant (p > .05). The trainer education effect was not significant, F(1, 305) = 2.91, p = .09, partial η2 = 0.01. The covariate effects were significant for online news-related self confidence with F(1, 305) = 7.64, p = .01, partial η2 = 0.02 (small effect)."
    }
  ],
  "Barzilai et al., Comput Educ (2023).": [
    {
      "Study": "1&2, Variable: Accuracy discernement",
      "Description": "Study comparing accuracy discernment between players of a misinformation game and a control group.",
      "N": 215,
      "Effect size": "Cohen's d: 0.49, 0.41",
      "Comments": "Accuracy discernment was higher among players of the misinformation game."
    },
    {
      "Study": "1&2, Variable: Sharing discernment",
      "Description": "Study comparing sharing discernment between players of a misinformation game and a control group.",
      "N": 215,
      "Effect size": "Cohen's d: 0.46, 0.59",
      "Comments": "Sharing discernment was higher among players of the misinformation game."
    },
    {
      "Study": "1&2, Variable: Stances regarding sharing misinformation",
      "Description": "Study comparing stances towards sharing COVID-19 misinformation between the experimental and control groups.",
      "N": 215,
      "Effect size": "Cohen's d: 0.02, 0.18",
      "Comments": "There were no significant differences in self-reported stances toward sharing COVID-19 misinformation between the experimental and control groups."
    },
    {
      "Study": "1&2, Variable: Metastrategic knowledge about evaluation strategies",
      "Description": "Study comparing the number of misinformation evaluation strategies described by players of a misinformation game and a control group.",
      "N": 215,
      "Effect size": "Cohen's d: 0.35, 0.41",
      "Comments": "In study 1, the difference failed to achieve significance. In Study 2, players of the misinformation game described a signficantly higher number of strategies than control group participants."
    }
  ],
  "Apuke & Gever, J Acad Libr (2023).": [
    {
      "Study": "1",
      "Description": "Pre- and post-intervention of participants' knowledge of social media.",
      "N": 235,
      "Effect size": "t-Value: 8.84",
      "Comments": "Participants in the treatment group reported a significant improvement in their knowledge of social media post-intervention."
    },
    {
      "Study": "1",
      "Description": "Pre- and post-intervention of participants' ability to recognize false news.",
      "N": 235,
      "Effect size": "t-Value: 7.23",
      "Comments": "The experimental group significantly outperformed the control group in identifying fake news post-intervention."
    },
    {
      "Study": "Table 5",
      "Description": "Pre- and post-intervention of participants' fake news verification capability.",
      "N": 235,
      "Effect size": "t-Value: 6.43",
      "Comments": "The treatment group's scores on their ability to verify information significantly improved post-intervention."
    },
    {
      "Study": "Table 6",
      "Description": "Pre- and post-intervention of participants likelihood of fake news sharing.",
      "N": 235,
      "Effect size": "t-Value: 8.43",
      "Comments": "The experimental group scored better in their ability to distinguish real news from fake news post-intervention."
    }
  ],
  "Resnick et al., preprint (2021).": [
    {
      "Study": "1",
      "Description": "The study investigated whether requirement to search for corroborating evidence either in a collective or individual research conditions would improve misinformation detection in lay people ratings (journalists' ratings were taken as a benchmark).",
      "N": 1301,
      "Effect size": "(no standard effect size available/yet extracted)",
      "Comments": "Lay raters in the two research conditions correlate with a journalist better than do raters in the no research condition. The individual research condition has greater power than the collective research condition for large groups of lay raters. In the individual research condition, 15 lay raters were equivalent to 3 journalists; even 54 raters were not sufficient to achieve the same power as three journalists in the collective search condition and in the no research condition."
    }
  ],
  "Guess et al., PNAS (2020).": [
    {
      "Study": "1: U.S. online",
      "Description": "Study 1 experimentally tested whether exposure to the media literacy intervention would cause a decrease in the perceived accuracy of false news articles.",
      "N": 4907,
      "Effect size": "Cohen’s d: 0.2",
      "Comments": "The media literacy treatment significantly reduced beliefs in false news articles. Wave 1 of the US study: a decrease of nearly 0.2 points on a 4-point scale (intent to treat [ITT]: β=−0.196, SE=0.020; P<0.005). Wave 2 of the US study: While the effect is still present weeks later, its magnitude attenuates by more than half relative to wave 1 (ITT, β=−0.080 [SE=0.019], P<0.005; ATT, β=−0.121 [SE=0.028], P<0.005)."
    },
    {
      "Study": "2: India online",
      "Description": "Study 2 experimentally tested whether exposure to the media literacy intervention would cause a decrease in the perceived accuracy of false news articles.",
      "N": 3273,
      "Effect size": "Cohen’s d: 0.11",
      "Comments": "The media literacy treatment significantly reduced beliefs in false news articles (ITT: β=−0.126, SE = 0.026; P<0.005) in the first wave of a two-wave survey. The study found no statistically reliable evidence that the treatment affected headline accuracy ratings among wave 2 respondents in either India sample."
    },
    {
      "Study": "3: India face-to-face",
      "Description": "Study 3 experimentally tested whether face-to-face exposure to the media literacy intervention would cause a decrease in the perceived accuracy of false news articles.",
      "N": 3744,
      "Effect size": "Cohen’s d: n.s.",
      "Comments": "The study found no evidence that the media literacy treatment systematically affected beliefs in false news stories or discrimination between false and mainstream news among India face-to-face respondents."
    }
  ],
  "Badrinathan, Am Political Sci Rev (2021).": [
    {
      "Study": "1",
      "Description": "This study experimentally tested whether an hour-long media literacy intervention would increase ability to identify misinformation among respondents in Bihar, India.",
      "N": 1224,
      "Effect size": "(no standard effect size available/yet extracted)",
      "Comments": "The study found no evidence that the intervention increased respondents' ability to identify misinformation, on average. While there was no average treatment effect, the interaction effect of the treatment on BJP partisans produces a negative effect on the ability to identify misinformation. For pro-BJP stories, the treatment effect for non-BJP supporters was 0.277, indicating that those who did not support the BJP and received the treatment identified an additional 0.277 stories. However, the treatment effect for BJP supporters was -0.135, indicating that those who supported the BJP and received the treatment identified 0.135 fewer stories."
    }
  ],
  "Ali & Qazi, JDE (2023).": [
    {
      "Study": "1",
      "Description": "The study aimed to evaluate the effectiveness of two educational interventions to counter misinformation among low-digital literacy populations. Treatment one = educational video. Treatment 2 = video + personalized feedback.",
      "N": 750,
      "Effect size": "Average treatment effect: 3.3",
      "Comments": "Treatment 1 does not have any significant impact. Participants who received treatment 2 were 5.6 percentage points (7.9%) more likely to correctly identify fake news relative to the control group. There is no significant effect on correctly identifying true news. As a result, the overall effect of treatment 2 on all news is 3.3 percentage points (4.5%), which points to improved discernment of news."
    }
  ],
  "Qian et al, J Comput-Mediat Comm (2023).": [
    {
      "Study": "1",
      "Description": "This study investigates the effects of active and passive interventions on the perceived credibility of visual posts and the intention to use the reverse image search in the future.",
      "N": 880,
      "Effect size": "F-statistic and Beta coefficient: F (2, 877) = 32.52 for intention to use reverse image search, B = 0.75 for active intervention, B = 0.53 for passive intervention",
      "Comments": "Active and passive interventions significantly increased the intention to use the reverse image search in the future compared to the control group. Active intervention was more effective than passive intervention."
    },
    {
      "Study": "1",
      "Description": "This study investigates whether digital media literacy would moderate the effects of intervention on discernment.",
      "N": 834,
      "Effect size": "F-statistic: F (2,831) = 0.994",
      "Comments": "Digital media literacy did not moderate the relationship between intervention and discernment."
    },
    {
      "Study": "1",
      "Description": "This study uses time spent on evaluating visual posts as a proxy measure to check if participants performed reverse image search.",
      "N": 894,
      "Effect size": "F-statistic: F (2, 891) = 12.08",
      "Comments": "Participants spent significantly longer time in the active intervention group when evaluating the four visual posts than in the passive and the control group."
    }
  ],
  "Kim et al., JMIS (2019).": [
    {
      "Study": "1",
      "Description": "Investigates the effect of rating mechanisms on the believability of articles.",
      "N": 590,
      "Effect size": "(no standard effect size available/yet extracted)",
      "Comments": "Ratings affected believability, with larger effects for low ratings than high ratings, and expert > user-article-based > user-source. Some smaller effects on reading/liking/sharing intentions.."
    },
    {
      "Study": "2",
      "Description": "Further investigates the effect of rating mechanisms and confirmation bias on the believability of articles.",
      "N": 299,
      "Effect size": "(no standard effect size available/yet extracted)",
      "Comments": "Only strongest effects survive (a low expert or user-article-based rating reducing believability)."
    }
  ],
  "Aslett et al, Sci Adv (2022).": [
    {
      "Study": "1",
      "Description": "The study focused on the impact of source reliability labels on the news consumption of online users.",
      "N": "968 for behavioral news consumption data collection",
      "Effect size": "(no standard effect size available/yet extracted)",
      "Comments": "The study found no significant effect of the source reliability labels on the quality of news consumption of online users. Even after the intervention, the news consumption patterns did not change significantly. However, a slight effect was observed among those who consume the most low-quality news. Relative to the average pretreatment value,  authors estimate a 5.4% increase in the treatment period and a 8.6% increase beginning July 1 in the average reliability score of news consumed."
    }
  ],
  "Shahid et al,  Proc. ACM Hum Comput Interact (2022).": [
    {
      "Effect size": "(no standard effect size available/yet extracted)"
    }
  ],
  "Celadin et al., Journal of Online Trust and Safety (2023).": [
    {
      "Study": "1",
      "Description": "Examination of the impact of fact-checker ratings on sharing of false headlines.",
      "N": 1627,
      "Effect size": "Beta coefficient: -0.08 (95%-CI: -0.12--0.05)",
      "Comments": "Sharing of false headlines was significantly reduced by the fact-checker ratings."
    },
    {
      "Study": "2",
      "Description": "Examination of the impact of layperson ratings on sharing of false headlines.",
      "N": 1627,
      "Effect size": "Beta coefficient: -0.04 (95%-CI: -0.08--0.01)",
      "Comments": "Sharing of false headlines was significantly reduced by the layperson ratings."
    }
  ],
  "Cookson et al., PLOS ONE (2021).": [
    {
      "Study": "1",
      "Description": "The study tested the effectiveness of a Social Norms intervention, which corrects misperceptions using normative feedback, to reduce UK parents’ anti-vaccine conspiracy beliefs and increase vaccination intentions.",
      "N": 202,
      "Effect size": "Partial eta squared (η2p): 0.03",
      "Comments": "There was a significant interaction between time and condition on belief in anti-vaccine conspiracy theories, indicating the effectiveness of the intervention, F(1.56, 253.27) = 4.73, p = .016, ηp2 = .03. There was no difference in belief in anti-vaccine conspiracy theories from baseline to the six-week follow up."
    }
  ],
  "Andi et al., Digit Journal (2021).": [
    {
      "Study": "1",
      "Description": "The study experimentally tested whether  a social norm-based message would impact participants' willingness to share a false news article.",
      "N": 1004,
      "Effect size": "(no standard effect size available/yet extracted)",
      "Comments": "5.17% reduction in willingness to share (SE = 0.02) or 27.5% reduction compared to control sharing (18.8%)"
    }
  ],
  "Ecker et al., QJEP (2022).": [
    {
      "Study": "1",
      "Description": "Experiment 1 tested whether social norms can reduce belief in a contested claim, and whether such an effect is dependent on the public nature of belief expressions. Experiment 1 also used a point norm (x out of 100 peers endorsed the claim).",
      "N": 143,
      "Effect size": "Cohen's d (private condition, pre-refutation norm): 0.31",
      "Comments": "mean belief-change scores (Belief Rating 2 – Belief Rating 1) differed significantly from zero in both the private condition, M = −0.29 (SD = 0.93), t(71) = −2.67, d = 0.31, p = .009, and the public condition, M = 0.37 (SD = 0.83), t(70) = −3.71, d = 0.44, p < .001. This demonstrated a small belief-reducing effect of the initial, pre-refutation norm."
    },
    {
      "Study": "2",
      "Description": "Experiment 2 again examined whether social-norm information can reduce the endorsement of questionable worldview-congruent claims, either in isolation or in combination with a refutation. Moreover, Experiment 2 used a distribution rather than a point norm.",
      "N": 144,
      "Effect size": "Cohen's d (narrow norm condition): 0.18",
      "Comments": "Change scores were significantly different from zero in the refutation condition of Experiment 2A, M = −1.53, SD = 1.76, d = 0.87, and all conditions of Experiment 2B (refutation: M = −1.75, SD = 1.98, d = 0.89; refutation-plus-narrow-norm: M = −1.61, SD = 2.14, d = 0.75; refutation-plus-wide-norm: M = −1.15, SD = 1.77, d = 0.65), all t(72) ⩽ 5.54, all p < .001. There was no significant belief change in the norm-only conditions of Experiment 2A (narrow: M = −0.21, SD = 1.15, d = 0.18; wide: M = −0.10, SD = 1.15, d = 0.08), t(72) ⩾ 1.54, p ⩾ .129. This established that claim belief was reduced significantly by a refutation (either with or without an additional norm) but not a stand-alone norm."
    },
    {
      "Study": "3",
      "Description": "Experiment 3 presented both claim-endorsement and predicted-estimates norms. Like in the Exp. 2, both norms used a distribution-based approach but with a larger number of data points; to facilitate this, a graphical presentation format was employed.",
      "N": 154,
      "Effect size": "Cohen's d (narrow norm condition): 0.77",
      "Comments": "Belief change was significantly different from zero in all conditions of Experiment 3A (refutation: M = −8.93, SD = 9.71, d = 0.92; narrow-norm: M = −8.11, SD = 10.54, d = 0.77; wide-norm: M = −6.55, SD = 10.15, d = 0.65), as well as all conditions of Experiment 3B (refutation: M = −10.00, SD = 18.45, d = 0.54; refutation-plus-narrow-norm: M = −18.66, SD = 17.29, d = 1.08; refutation-plus-wide-norm: M = −15.04, SD = 14.36, d = 1.05), all t(75/77) ⩽ 4.79, all p < .001, establishing that claim belief was reduced significantly by a refutation or either type of norm."
    }
  ],
  "Prike et al, preprint (2023).": [
    {
      "Study": "1. Credibility badges, engagement",
      "Description": "The study investigates the impact of credibility badges on engagement with social media posts containing false claims.",
      "N": 411,
      "Effect size": "Eta squared (ηp2): 0.09 (95%-CI: 0.04-0.15)",
      "Comments": "There was a significant main effect of credibility badge, with less positive engagements when credibility badges were included."
    },
    {
      "Study": "2. Social norms, engagement",
      "Description": "The study examines the effect of social norms on engagement with social media posts containing false claims.",
      "N": 411,
      "Effect size": "Eta squared (ηp2): 0.01 (95%-CI: 0-0.04)",
      "Comments": "There was a significant main effect of social norm, with less positive engagements when a social norm was included."
    },
    {
      "Study": "3. Credibility badges, beliefs",
      "Description": "The study explores the impact of credibility badges on beliefs in false claims.",
      "N": 411,
      "Effect size": "Eta squared (ηp2): 0.03 (95%-CI: 0.01-0.07)",
      "Comments": "The presence of a credibility badge significantly reduced belief in false claims."
    },
    {
      "Study": "4. Social norms, beliefs",
      "Description": "The study investigates the effect of social norms on beliefs in false claims.",
      "N": 411,
      "Effect size": "Eta squared (ηp2): 0.02 (95%-CI: 0-0.05)",
      "Comments": "The presence of a social norm intervention significantly reduced belief in false claims."
    }
  ],
  "Ecker et al., (2010). Mem Cogn.": [
    {
      "Study": "1",
      "Description": "Study 1 experimentally tested whether the continued influence of misinformation can be reduced by explicitly warning people at the outset that they may be misled.",
      "N": 125,
      "Effect size": "(no standard effect size available/yet extracted)",
      "Comments": "A general warning did not reduce the level of continued influence effect (CIE) found with a mere retraction. Both a specific warning and the provision of an alternative explanation strongly reduced the CIE The alternative and the specific warning reduced references to misinformation  by 51%–65% (42%–67% in the alternative condition, 53%–63% in the specific warning condition)."
    },
    {
      "Study": "2",
      "Description": "Study 2 experimentally tested whether alerting people to the effects of misinformation could eliminate the CIE in cases in which there is alternative information available.",
      "N": 92,
      "Effect size": "(no standard effect size available/yet extracted)",
      "Comments": "The combined effect of the specific warning and the provision of an alternative account reduced reliance on misinformation more than the constituent strategies alone."
    }
  ],
  "Kim et al., Manag Inf Syst (2019).": [
    {
      "Study": "1",
      "Description": "Study tested the effectiveness of three different types of source ratings: expert rating, user article rating and user source rating.",
      "N": 590,
      "Effect size": "(no standard effect size available/yet extracted)",
      "Comments": "When ratings were high, both expert rating and user article rating had significant effects, but user source ratings had no effect. For low-rated sources, all three mechanisms had significant effects; expert ratings had stronger impacts than did user source ratings (Chi-Squared = 15.39, 𝑝<0.001), as did user article ratings (Chi-Squared = 4.87, 𝑝<0.05); there was, however, no significant differences between expert rating and user article rating (Chi-Squared = 2.89, 𝑝>0.05)."
    },
    {
      "Study": "2",
      "Description": "Study tested the effectiveness of three different types of source ratings: expert rating, user article rating and user source rating.",
      "N": 299,
      "Effect size": "(no standard effect size available/yet extracted)",
      "Comments": "High ratings had no significant effect across all rating mechanisms, while low ratings from expert rating and user article rating mechanisms had a negative influence on believability (H2 is partially supported); user source ratings had no effect. Comparing the rating mechanisms that had significant effects, there were no differences in the effects of the expert rating and user article rating mechanisms for low ratings (Chi-Squared = 0.64, p >.05)."
    }
  ],
  "Mena, Pol & Int (2019).": [
    {
      "Study": "1",
      "Description": "This study experimentally tests the effectiveness of warning labels designed to reduce the sharing of false news.",
      "N": 501,
      "Effect size": "Cohen’s d: 0.36",
      "Comments": "The flagging of false news had a small to moderate effect on decreasing the likelihood of sharing the fabricated post on Facebook."
    }
  ],
  "Clayton et al., Political Behav (2020).": [
    {
      "Study": "1: General warning",
      "Description": "Participants received a general warning about misleading articles",
      "N": 1250,
      "Effect size": "Cohen’s d: 0.08",
      "Comments": "Average belief in false headlines was slightly lower for participants who saw a general warning before seeing headlines than for participants who saw headlines with no warning (− 0.08; p < .05). However, the substantive magnitude of this reduction in perceived belief accuracy is small (Cohen’s d = 0.08)."
    },
    {
      "Study": "1: Disputed tag",
      "Description": "Specific headlines are accompanied by a Disputed tag.",
      "N": 429,
      "Effect size": "Cohen’s d: 0.26",
      "Comments": "Average perceived accuracy for participants who saw a headline with a Disputed tag was 0.24 points lower on our four-point scale than for participants who saw no tag (p < 0.01; Cohen’s d = 0.26)."
    },
    {
      "Study": "1: Rated False tag",
      "Description": "Specific headlines are accompanied by a Rated False tag.",
      "N": 397,
      "Effect size": "Cohen’s d: 0.38",
      "Comments": "Average perceived accuracy for participants who saw a headline with a Rated False tag was 0.34 points lower on our four-point scale than for participants who saw no tag (p < 0.01; Cohen’s d = 0.38)."
    }
  ],
  "Pennycook et al., Manag Sci (2020).": [
    {
      "Study": "1",
      "Description": "Study 1 tests the predictions regarding the existence of a warning effect and an implied truth effect when warnings are attached to a subset of false headlines.",
      "N": 5271,
      "Effect size": "(no standard effect size available/yet extracted)",
      "Comments": "The warning decreases belief in items that are tagged (the warning effect) but increases belief in items that are untagged (the implied truth effect). Both the warning effect and the implied truth effect were quite small. Warning effect: False headlines in the warning treatment that were presented with warnings were perceived as less accurate (M=0.187) than false headlines in the control (M=0.220). The warning effect was roughly twice as large for politically concordant headlines (warning, M= 0.210; control, M= 0.253) as for politically discordant headlines (warning, M= 0.187; control, M=0.164)"
    },
    {
      "Study": "2",
      "Description": "Study 2 tests whether the effects found in Study 1 generalize to sharing intentions.",
      "N": 1568,
      "Effect size": "(no standard effect size available/yet extracted)",
      "Comments": "Participants were less likely to consider sharing false headlines tagged with a warning (16.1%) compared with false headlines in the control (29.8%; p<0.001). The warning effect was significantly larger for concordant false headlines (warned: 16.7%; control: 33.7%) than for discordant false headlines (warned: 14.7%; control: 26.0%)."
    }
  ],
  "Ecker et al., Brit Psych Soc (2020).": [
    {
      "Study": "1",
      "Description": "The experiments used true and false claims across various experimental conditions; claim veracity was manipulated within subjects, and experimental condition was a between-subjects factor.",
      "N": 531,
      "Effect size": "Partial eta squared (η2p): 0.01",
      "Comments": "Refutations were not more effective than plain retractions at reducing claim belief after a 1-day retention interval."
    },
    {
      "Study": "1",
      "Description": "The experiments used true and false claims across various experimental conditions; claim veracity was manipulated within subjects, and experimental condition was a between-subjects factor.",
      "N": 369,
      "Effect size": "Partial eta squared (η2p): 0.03",
      "Comments": "Refutations are more effective than plain false-tag retractions at reducing claim belief after a 1-week retention interval."
    },
    {
      "Study": "12",
      "Description": "The experiments used true and false claims across various experimental conditions; claim veracity was manipulated within subjects, and experimental condition was a between-subjects factor.",
      "N": 900,
      "Effect size": "Partial eta squared (η2p): Study 1: 0.12; Study 2: 0.03",
      "Comments": "Detailed refutations lead to lower inferential-reasoning scores compared to plain retractions."
    },
    {
      "Study": "1; 2",
      "Description": "The experiments used true and false claims across various experimental conditions; claim veracity was manipulated within subjects, and experimental condition was a between-subjects factor.",
      "N": 900,
      "Effect size": "Partial eta squared (η2p): Study 1: 0.03; Study 2: 0.1",
      "Comments": "Refutations might reduce belief in true claims."
    }
  ],
  "Grady et al., Cogn Res: Princ Implic (2021).": [
    {
      "Study": "1",
      "Description": "Study 2 experimentally tested whether subtly making the concept of accuracy salient increased the quality of COVID-19 information that people were willing to share online.",
      "N": 418,
      "Effect size": "(no standard effect size available/yet extracted)",
      "Comments": "Participants in the Warning-Before condition believed the false news items less than those the Warning-After condition for both the congruent (b = 1.283, SE = 0.149, p < 0.001) and incongruent (b = 0.734, SE = .120, p < 0.001) items, while the interaction shows that the former was especially pronounced."
    }
  ],
  "Lee et al., Health Comm (2023).": [
    {
      "Study": "1",
      "Description": "Examined the effectiveness of fact-checking labels in reducing vaccine conspiracy beliefs",
      "N": 206,
      "Effect size": "Cohen's d: -0.28 (95%-CI: -0.53--0.03)",
      "Comments": "Fact-checking had a small negative effect on vaccine conspiracy beliefs"
    },
    {
      "Study": "1",
      "Description": "Examined the effectiveness of fact-checking labels on misinformation engagement intentions",
      "N": 206,
      "Effect size": "Cohen's d: -0.21 (95%-CI: -0.46-0.04)",
      "Comments": "There was no statistically significant effect of fact-checking on misinformation engagement intentions."
    },
    {
      "Study": "1",
      "Description": "Examined the effectiveness of fact-checking labels on vaccination intentions",
      "N": 206,
      "Effect size": "Cohen's d: -0.05 (95%-CI: -0.3-0.2)",
      "Comments": "There was no statistically significant effect of fact-checking on vaccination intentions"
    }
  ],
  "Koch et al, J App Soc Psych (2023).": [
    {
      "Study": "1",
      "Description": "This study experimentally tested the effect of warning labels on a fake news post to measure perceived credibility .",
      "N": 571,
      "Effect size": "R-squared (R²): 0.04",
      "Comments": "Warning labels reduced the perceived credibility of fake news posts. Social endorsement cues had no such effect on credibility perceptions."
    },
    {
      "Study": "1",
      "Description": "This study experimentally tested the effect of warning labels on a fake news post to measure amplification likelihood",
      "N": 571,
      "Effect size": "R-squared (R²): 0.05",
      "Comments": "Participants who saw the warning label reported a lower likelihood that they would amplify the fake news post. Social endorsement cues had no significant effect."
    },
    {
      "Study": "1",
      "Description": "This study experimentally tested the effect of warning labels on a fake news post to measure elaboration likelihood.",
      "N": 571,
      "Effect size": "R-squared (R²): 0.05",
      "Comments": "Neither warning labels nor social endorsement or their interaction predicted participants' elaboration likelihood."
    }
  ],
  "Moon et al, Mass Comm and Soc (2023).": [
    {
      "Study": "H1",
      "Description": "Comparison of participants' perceived credibility of a false news story about COVID-19 based on in-group and out-group news condition.",
      "N": 353,
      "Effect size": "η2 (partial eta): 0.01",
      "Comments": "Those who read an article from their supporting party reported greater perceived credibility than those who read from their opponent party."
    },
    {
      "Study": "H2",
      "Description": "Perception of the credibility of fact-checking messages based on the in-group and out-group condition.",
      "N": 353,
      "Effect size": "η2: 0.01",
      "Comments": "Participants in the in-group condition were less likely to perceive fact-checking messages as credible than those in the out-group condition."
    },
    {
      "Study": "H3",
      "Description": "Investigation of the effectiveness of alternative fact-checking sources in decreasing motivated reasoning.",
      "N": 349,
      "Effect size": "η2: 0.02",
      "Comments": "The pattern of motivated reasoning varied by fact-checking sources, with significant differences observed when the fact-checker was a human expert."
    }
  ]
}
